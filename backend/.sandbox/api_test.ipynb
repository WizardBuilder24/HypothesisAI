{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562ab5e9",
   "metadata": {},
   "source": [
    "# Preprint APIs Testing Notebook\n",
    "\n",
    "This notebook tests all the preprint server APIs implemented in `preprint_apis.py`.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4345d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from agent.tools.preprint_apis import (\n",
    "    ArxivAPI,\n",
    "    BioRxivAPI,\n",
    "    ChemRxivAPI,\n",
    "    SSRNApi,\n",
    "    ResearchSquareAPI,\n",
    "    PreprintAggregator,\n",
    "    Paper\n",
    ")\n",
    "\n",
    "# Test queries for different domains\n",
    "TEST_QUERIES = {\n",
    "    'physics': 'quantum computing',\n",
    "    'biology': 'CRISPR gene editing',\n",
    "    'medicine': 'COVID-19 vaccine',\n",
    "    'chemistry': 'organic synthesis',\n",
    "    'computer_science': 'machine learning',\n",
    "    'economics': 'behavioral economics',\n",
    "    'general': 'climate change'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50801f0f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edbccf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def print_paper_summary(paper: Paper, index: int = None):\n",
    "    \"\"\"Print a formatted summary of a paper\"\"\"\n",
    "    prefix = f\"{index}. \" if index is not None else \"\"\n",
    "    print(f\"{prefix}{paper.title[:80]}...\")\n",
    "    print(f\"   Authors: {', '.join(paper.authors[:3])}{'...' if len(paper.authors) > 3 else ''}\")\n",
    "    print(f\"   Source: {paper.source} | Date: {paper.date_published.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   Relevance: {paper.relevance_score:.2f} | Quality: {paper.quality_score:.2f}\")\n",
    "    print(f\"   DOI: {paper.doi or 'N/A'}\")\n",
    "    print(f\"   Categories: {', '.join(paper.categories[:3]) if paper.categories else 'N/A'}\")\n",
    "    print(f\"   URL: {paper.url}\")\n",
    "    print()\n",
    "\n",
    "def test_api_results(papers: list, api_name: str, query: str):\n",
    "    \"\"\"Test and display API results\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìö {api_name} API Results for: '{query}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not papers:\n",
    "        print(\"‚ùå No papers found\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(papers)} papers\")\n",
    "    print(\"\\nTop 3 results:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for i, paper in enumerate(papers[:3], 1):\n",
    "        print_paper_summary(paper, i)\n",
    "    \n",
    "    return True\n",
    "\n",
    "async def test_api_with_timeout(api_func, timeout: int = 30):\n",
    "    \"\"\"Test API function with timeout\"\"\"\n",
    "    try:\n",
    "        return await asyncio.wait_for(api_func(), timeout=timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"‚è∞ Request timed out after {timeout} seconds\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9961e40",
   "metadata": {},
   "source": [
    "## 1. ArXiv API Testing\n",
    "\n",
    "Testing the arXiv API with physics and computer science queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a64f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìö ArXiv API Results for: 'all:\"deep learning\"'\n",
      "============================================================\n",
      "‚úÖ Found 10 papers\n",
      "\n",
      "Top 3 results:\n",
      "----------------------------------------\n",
      "1. One Model To Learn Them All...\n",
      "   Authors: Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer...\n",
      "   Source: arxiv | Date: 2017-06-16\n",
      "   Relevance: 0.11 | Quality: 0.40\n",
      "   DOI: N/A\n",
      "   Categories: cs.LG, stat.ML\n",
      "   URL: http://arxiv.org/abs/1706.05137v1\n",
      "\n",
      "2. DCoM: Active Learning for All Learners...\n",
      "   Authors: Inbal Mishal, Daphna Weinshall\n",
      "   Source: arxiv | Date: 2024-07-01\n",
      "   Relevance: 0.22 | Quality: 0.53\n",
      "   DOI: N/A\n",
      "   Categories: cs.LG\n",
      "   URL: http://arxiv.org/abs/2407.01804v2\n",
      "\n",
      "3. Learning One Representation to Optimize All Rewards...\n",
      "   Authors: Ahmed Touati, Yann Ollivier\n",
      "   Source: arxiv | Date: 2021-03-14\n",
      "   Relevance: 0.16 | Quality: 0.55\n",
      "   DOI: N/A\n",
      "   Categories: cs.LG, cs.AI, math.OC\n",
      "   URL: http://arxiv.org/abs/2103.07945v3\n",
      "\n",
      "\n",
      "üîç Testing get_paper for ID: 1706.05137v1\n",
      "‚úÖ Successfully retrieved specific paper\n",
      "One Model To Learn Them All...\n",
      "   Authors: Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer...\n",
      "   Source: arxiv | Date: 2017-06-16\n",
      "   Relevance: 0.00 | Quality: 0.40\n",
      "   DOI: N/A\n",
      "   Categories: cs.LG, stat.ML\n",
      "   URL: http://arxiv.org/abs/1706.05137v1\n",
      "\n",
      "\n",
      "ArXiv API Test: ‚úÖ PASSED\n",
      "‚úÖ Successfully retrieved specific paper\n",
      "One Model To Learn Them All...\n",
      "   Authors: Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer...\n",
      "   Source: arxiv | Date: 2017-06-16\n",
      "   Relevance: 0.00 | Quality: 0.40\n",
      "   DOI: N/A\n",
      "   Categories: cs.LG, stat.ML\n",
      "   URL: http://arxiv.org/abs/1706.05137v1\n",
      "\n",
      "\n",
      "ArXiv API Test: ‚úÖ PASSED\n"
     ]
    }
   ],
   "source": [
    "async def test_arxiv_api():\n",
    "    \"\"\"Test ArXiv API\"\"\"\n",
    "    query = TEST_QUERIES['physics']\n",
    "\n",
    "    query = 'all:\"deep learning\"'\n",
    "    \n",
    "    async with ArxivAPI() as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=10)\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"ArXiv\", query)\n",
    "        \n",
    "        # Test getting a specific paper\n",
    "        if papers:\n",
    "            paper_id = papers[0].id\n",
    "            print(f\"\\nüîç Testing get_paper for ID: {paper_id}\")\n",
    "            specific_paper = await api.get_paper(paper_id)\n",
    "            if specific_paper:\n",
    "                print(\"‚úÖ Successfully retrieved specific paper\")\n",
    "                print_paper_summary(specific_paper)\n",
    "            else:\n",
    "                print(\"‚ùå Failed to retrieve specific paper\")\n",
    "        \n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "arxiv_success = await test_arxiv_api()\n",
    "print(f\"\\nArXiv API Test: {'‚úÖ PASSED' if arxiv_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358c142",
   "metadata": {},
   "source": [
    "## 2. BioRxiv API Testing\n",
    "\n",
    "Testing the bioRxiv API with biology queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88595de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: '>' not supported between instances of 'str' and 'int'\n",
      "\n",
      "============================================================\n",
      "üìö BioRxiv API Results for: 'CRISPR gene editing'\n",
      "============================================================\n",
      "‚ùå No papers found\n",
      "\n",
      "BioRxiv API Test: ‚ùå FAILED\n"
     ]
    }
   ],
   "source": [
    "async def test_biorxiv_api():\n",
    "    \"\"\"Test BioRxiv API\"\"\"\n",
    "    query = TEST_QUERIES['biology']\n",
    "    \n",
    "    async with BioRxivAPI(server='biorxiv') as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=5),\n",
    "            timeout=45  # BioRxiv can be slower\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"BioRxiv\", query)\n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "biorxiv_success = await test_biorxiv_api()\n",
    "print(f\"\\nBioRxiv API Test: {'‚úÖ PASSED' if biorxiv_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f91e59",
   "metadata": {},
   "source": [
    "## 3. MedRxiv API Testing\n",
    "\n",
    "Testing the medRxiv API with medical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_medrxiv_api():\n",
    "    \"\"\"Test MedRxiv API\"\"\"\n",
    "    query = TEST_QUERIES['medicine']\n",
    "    \n",
    "    async with BioRxivAPI(server='medrxiv') as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=5),\n",
    "            timeout=45\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"MedRxiv\", query)\n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "medrxiv_success = await test_medrxiv_api()\n",
    "print(f\"\\nMedRxiv API Test: {'‚úÖ PASSED' if medrxiv_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac0fab",
   "metadata": {},
   "source": [
    "## 4. ChemRxiv API Testing\n",
    "\n",
    "Testing the ChemRxiv API with chemistry queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eae8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_chemrxiv_api():\n",
    "    \"\"\"Test ChemRxiv API\"\"\"\n",
    "    query = TEST_QUERIES['chemistry']\n",
    "    \n",
    "    async with ChemRxivAPI() as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=5),\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"ChemRxiv\", query)\n",
    "        \n",
    "        # Test getting a specific paper\n",
    "        if papers:\n",
    "            paper_id = papers[0].id\n",
    "            print(f\"\\nüîç Testing get_paper for ID: {paper_id}\")\n",
    "            specific_paper = await api.get_paper(paper_id)\n",
    "            if specific_paper:\n",
    "                print(\"‚úÖ Successfully retrieved specific paper\")\n",
    "                print_paper_summary(specific_paper)\n",
    "            else:\n",
    "                print(\"‚ùå Failed to retrieve specific paper\")\n",
    "        \n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "chemrxiv_success = await test_chemrxiv_api()\n",
    "print(f\"\\nChemRxiv API Test: {'‚úÖ PASSED' if chemrxiv_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de15435",
   "metadata": {},
   "source": [
    "## 5. SSRN API Testing\n",
    "\n",
    "Testing the SSRN API with economics queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_ssrn_api():\n",
    "    \"\"\"Test SSRN API\"\"\"\n",
    "    query = TEST_QUERIES['economics']\n",
    "    \n",
    "    async with SSRNApi() as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=5),\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"SSRN\", query)\n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "ssrn_success = await test_ssrn_api()\n",
    "print(f\"\\nSSRN API Test: {'‚úÖ PASSED' if ssrn_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f765f",
   "metadata": {},
   "source": [
    "## 6. Research Square API Testing\n",
    "\n",
    "Testing the Research Square API with general scientific queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_researchsquare_api():\n",
    "    \"\"\"Test Research Square API\"\"\"\n",
    "    query = TEST_QUERIES['general']\n",
    "    \n",
    "    async with ResearchSquareAPI() as api:\n",
    "        papers = await test_api_with_timeout(\n",
    "            lambda: api.search(query, max_results=5),\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        success = test_api_results(papers, \"Research Square\", query)\n",
    "        \n",
    "        # Test getting a specific paper\n",
    "        if papers:\n",
    "            paper_id = papers[0].id\n",
    "            print(f\"\\nüîç Testing get_paper for ID: {paper_id}\")\n",
    "            specific_paper = await api.get_paper(paper_id)\n",
    "            if specific_paper:\n",
    "                print(\"‚úÖ Successfully retrieved specific paper\")\n",
    "                print_paper_summary(specific_paper)\n",
    "            else:\n",
    "                print(\"‚ùå Failed to retrieve specific paper\")\n",
    "        \n",
    "        return success\n",
    "\n",
    "# Run the test\n",
    "rs_success = await test_researchsquare_api()\n",
    "print(f\"\\nResearch Square API Test: {'‚úÖ PASSED' if rs_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c826a53",
   "metadata": {},
   "source": [
    "## 7. Preprint Aggregator Testing\n",
    "\n",
    "Testing the main aggregator that combines results from multiple APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19965672",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_aggregator():\n",
    "    \"\"\"Test the Preprint Aggregator\"\"\"\n",
    "    aggregator = PreprintAggregator()\n",
    "    \n",
    "    # Test field detection\n",
    "    print(\"üß† Testing field detection:\")\n",
    "    for field, query in TEST_QUERIES.items():\n",
    "        detected = aggregator.detect_field(query)\n",
    "        print(f\"   '{query}' ‚Üí {detected}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Test aggregated search\n",
    "    query = \"machine learning for drug discovery\"\n",
    "    print(f\"üîç Testing aggregated search for: '{query}'\")\n",
    "    \n",
    "    papers = await test_api_with_timeout(\n",
    "        lambda: aggregator.search_all(\n",
    "            query=query,\n",
    "            max_results_per_server=5\n",
    "        ),\n",
    "        timeout=60\n",
    "    )\n",
    "    \n",
    "    if papers:\n",
    "        print(f\"\\n‚úÖ Aggregated search found {len(papers)} unique papers\")\n",
    "        print(\"\\nTop 5 ranked results:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, paper in enumerate(papers[:5], 1):\n",
    "            ranking_score = paper.metadata.get('ranking_score', 0)\n",
    "            print(f\"\\n{i}. [{paper.source}] {paper.title[:70]}...\")\n",
    "            print(f\"   Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "            print(f\"   Date: {paper.date_published.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"   Scores - Relevance: {paper.relevance_score:.2f}, Quality: {paper.quality_score:.2f}, Ranking: {ranking_score:.2f}\")\n",
    "            print(f\"   URL: {paper.url}\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ùå Aggregated search failed\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "aggregator_success = await test_aggregator()\n",
    "print(f\"\\nAggregator Test: {'‚úÖ PASSED' if aggregator_success else '‚ùå FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75992218",
   "metadata": {},
   "source": [
    "## 8. Performance and Reliability Testing\n",
    "\n",
    "Testing the APIs under different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_performance():\n",
    "    \"\"\"Test API performance and reliability\"\"\"\n",
    "    print(\"‚ö° Performance Testing\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    apis_to_test = [\n",
    "        ('ArXiv', ArxivAPI(), 'quantum computing'),\n",
    "        ('BioRxiv', BioRxivAPI(server='biorxiv'), 'gene therapy'),\n",
    "        ('ChemRxiv', ChemRxivAPI(), 'catalysis')\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for api_name, api, query in apis_to_test:\n",
    "        print(f\"\\nüîç Testing {api_name}...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            async with api:\n",
    "                papers = await asyncio.wait_for(\n",
    "                    api.search(query, max_results=5),\n",
    "                    timeout=30\n",
    "                )\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds()\n",
    "                \n",
    "                results[api_name] = {\n",
    "                    'success': True,\n",
    "                    'papers_found': len(papers),\n",
    "                    'duration_seconds': duration,\n",
    "                    'avg_relevance': sum(p.relevance_score for p in papers) / len(papers) if papers else 0,\n",
    "                    'avg_quality': sum(p.quality_score for p in papers) / len(papers) if papers else 0\n",
    "                }\n",
    "                \n",
    "                print(f\"   ‚úÖ Success: {len(papers)} papers in {duration:.2f}s\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            results[api_name] = {\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'duration_seconds': duration\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nüìä Performance Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for api_name, result in results.items():\n",
    "        if result['success']:\n",
    "            print(f\"{api_name:15} | {result['papers_found']:2d} papers | {result['duration_seconds']:5.2f}s | Rel: {result['avg_relevance']:.2f} | Qual: {result['avg_quality']:.2f}\")\n",
    "        else:\n",
    "            print(f\"{api_name:15} | FAILED after {result['duration_seconds']:.2f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run performance test\n",
    "perf_results = await test_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11c1c8",
   "metadata": {},
   "source": [
    "## 9. Edge Case Testing\n",
    "\n",
    "Testing APIs with edge cases and unusual queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_edge_cases():\n",
    "    \"\"\"Test edge cases and error handling\"\"\"\n",
    "    print(\"üß™ Edge Case Testing\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    edge_cases = [\n",
    "        ('empty_query', ''),\n",
    "        ('single_char', 'a'),\n",
    "        ('special_chars', '!@#$%^&*()'),\n",
    "        ('very_long', 'machine learning artificial intelligence deep neural networks ' * 10),\n",
    "        ('non_english', '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'),\n",
    "        ('numbers_only', '12345'),\n",
    "        ('very_specific', 'CRISPR-Cas9 mediated knockout of BRCA1 in HEK293T cells')\n",
    "    ]\n",
    "    \n",
    "    # Test with ArXiv API (most reliable)\n",
    "    async with ArxivAPI() as api:\n",
    "        for case_name, query in edge_cases:\n",
    "            print(f\"\\nüîç Testing: {case_name}\")\n",
    "            print(f\"   Query: '{query[:50]}{'...' if len(query) > 50 else ''}'\")\n",
    "            \n",
    "            try:\n",
    "                papers = await asyncio.wait_for(\n",
    "                    api.search(query, max_results=3),\n",
    "                    timeout=15\n",
    "                )\n",
    "                print(f\"   ‚úÖ Success: {len(papers)} papers found\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Edge case testing completed\")\n",
    "\n",
    "# Run edge case tests\n",
    "await test_edge_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5b5bc",
   "metadata": {},
   "source": [
    "## 10. Final Test Summary\n",
    "\n",
    "Summary of all test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_summary():\n",
    "    \"\"\"Print final test summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã FINAL TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Individual API tests\n",
    "    api_tests = [\n",
    "        ('ArXiv API', arxiv_success),\n",
    "        ('BioRxiv API', biorxiv_success),\n",
    "        ('MedRxiv API', medrxiv_success),\n",
    "        ('ChemRxiv API', chemrxiv_success),\n",
    "        ('SSRN API', ssrn_success),\n",
    "        ('Research Square API', rs_success),\n",
    "        ('Aggregator', aggregator_success)\n",
    "    ]\n",
    "    \n",
    "    passed = sum(1 for _, success in api_tests if success)\n",
    "    total = len(api_tests)\n",
    "    \n",
    "    print(f\"\\nüß™ API Tests: {passed}/{total} passed\")\n",
    "    for test_name, success in api_tests:\n",
    "        status = \"‚úÖ PASS\" if success else \"‚ùå FAIL\"\n",
    "        print(f\"   {test_name:20} | {status}\")\n",
    "    \n",
    "    # Performance summary\n",
    "    if 'perf_results' in globals():\n",
    "        successful_apis = sum(1 for result in perf_results.values() if result['success'])\n",
    "        print(f\"\\n‚ö° Performance Tests: {successful_apis}/{len(perf_results)} APIs responded\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    if passed >= total * 0.7:  # 70% pass rate\n",
    "        print(f\"\\nüéâ OVERALL: GOOD - {passed}/{total} APIs working properly\")\n",
    "    elif passed >= total * 0.5:  # 50% pass rate\n",
    "        print(f\"\\n‚ö†Ô∏è  OVERALL: PARTIAL - {passed}/{total} APIs working, some issues detected\")\n",
    "    else:\n",
    "        print(f\"\\nüö® OVERALL: POOR - Only {passed}/{total} APIs working, significant issues\")\n",
    "    \n",
    "    print(\"\\nüí° Next Steps:\")\n",
    "    print(\"   - Fix any failing APIs\")\n",
    "    print(\"   - Monitor rate limits during heavy usage\")\n",
    "    print(\"   - Consider implementing caching for frequently accessed papers\")\n",
    "    print(\"   - Add retry logic for transient failures\")\n",
    "\n",
    "# Print final summary\n",
    "print_test_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febd5fd",
   "metadata": {},
   "source": [
    "## 11. Save Test Results\n",
    "\n",
    "Save test results to a JSON file for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_results():\n",
    "    \"\"\"Save test results to file\"\"\"\n",
    "    test_results = {\n",
    "        'test_timestamp': datetime.now().isoformat(),\n",
    "        'api_tests': {\n",
    "            'arxiv': arxiv_success,\n",
    "            'biorxiv': biorxiv_success,\n",
    "            'medrxiv': medrxiv_success,\n",
    "            'chemrxiv': chemrxiv_success,\n",
    "            'ssrn': ssrn_success,\n",
    "            'research_square': rs_success,\n",
    "            'aggregator': aggregator_success\n",
    "        },\n",
    "        'performance_results': perf_results if 'perf_results' in globals() else {},\n",
    "        'test_queries': TEST_QUERIES,\n",
    "        'summary': {\n",
    "            'total_tests': 7,\n",
    "            'passed_tests': sum([\n",
    "                arxiv_success, biorxiv_success, medrxiv_success,\n",
    "                chemrxiv_success, ssrn_success, rs_success, aggregator_success\n",
    "            ]),\n",
    "            'success_rate': sum([\n",
    "                arxiv_success, biorxiv_success, medrxiv_success,\n",
    "                chemrxiv_success, ssrn_success, rs_success, aggregator_success\n",
    "            ]) / 7\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    output_file = f\"api_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(test_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nüíæ Test results saved to: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Save results\n",
    "results_file = save_test_results()\n",
    "print(f\"\\nüèÅ Testing complete! Results saved to {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce55051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3Aelectron%26id_list%3D%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=all:electron&amp;id_list=&amp;start=0&amp;max_results=1</title>\n",
      "  <id>http://arxiv.org/api/cHxbiOdZaP56ODnBPIenZhzg5f8</id>\n",
      "  <updated>2025-08-22T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">228634</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/cond-mat/0102536v1</id>\n",
      "    <updated>2001-02-28T20:12:09Z</updated>\n",
      "    <published>2001-02-28T20:12:09Z</published>\n",
      "    <title>Impact of Electron-Electron Cusp on Configuration Interaction Energies</title>\n",
      "    <summary>  The effect of the electron-electron cusp on the convergence of configuration\n",
      "interaction (CI) wave functions is examined. By analogy with the\n",
      "pseudopotential approach for electron-ion interactions, an effective\n",
      "electron-electron interaction is developed which closely reproduces the\n",
      "scattering of the Coulomb interaction but is smooth and finite at zero\n",
      "electron-electron separation. The exact many-electron wave function for this\n",
      "smooth effective interaction has no cusp at zero electron-electron separation.\n",
      "We perform CI and quantum Monte Carlo calculations for He and Be atoms, both\n",
      "with the Coulomb electron-electron interaction and with the smooth effective\n",
      "electron-electron interaction. We find that convergence of the CI expansion of\n",
      "the wave function for the smooth electron-electron interaction is not\n",
      "significantly improved compared with that for the divergent Coulomb interaction\n",
      "for energy differences on the order of 1 mHartree. This shows that, contrary to\n",
      "popular belief, description of the electron-electron cusp is not a limiting\n",
      "factor, to within chemical accuracy, for CI calculations.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>David Prendergast</name>\n",
      "      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>M. Nolan</name>\n",
      "      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NMRC, University College, Cork, Ireland</arxiv:affiliation>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Claudia Filippi</name>\n",
      "      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Stephen Fahy</name>\n",
      "      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>J. C. Greer</name>\n",
      "      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NMRC, University College, Cork, Ireland</arxiv:affiliation>\n",
      "    </author>\n",
      "    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1063/1.1383585</arxiv:doi>\n",
      "    <link title=\"doi\" href=\"http://dx.doi.org/10.1063/1.1383585\" rel=\"related\"/>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 6 figures, 3 tables, LaTeX209, submitted to The Journal of\n",
      "  Chemical Physics</arxiv:comment>\n",
      "    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Chem. Phys. 115, 1626 (2001)</arxiv:journal_ref>\n",
      "    <link href=\"http://arxiv.org/abs/cond-mat/0102536v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cond-mat/0102536v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cond-mat.str-el\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cond-mat.str-el\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib, urllib.request\n",
    "import xmltodict\n",
    "url = 'http://export.arxiv.org/api/query?search_query=all:electron&start=0&max_results=1'\n",
    "data = urllib.request.urlopen(url)\n",
    "parsed_data = xmltodict.parse(data.read())\n",
    "print(parsed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690e2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
